\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{lipsum}
\usepackage{algorithm}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amsmath,amsfonts}
\usepackage{array,booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{stackrel}
\usepackage{breqn}
% \usepackage{isomath}
\usepackage{mathtools}
% http://ctan.org/pkg/amsmath
\newcommand\sufr[3][0pt]{$\rule{0pt}{\dimexpr#1+1.4ex\relax}^\frac{#2}{#3}$}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Democratic Algorithm: A Novel Approach to Hierarchical Swarm Intelligence\\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
% should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

% \author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% }

\maketitle

\begin{abstract}
Computational intelligence has produced nature inspired algorithms as the new and popular problem solving tool in multi-objective optimization problems. In this paper we present Democratic Algorithm (DA), a social-construct based algorithm heavily inspired from hierarchy swarm intelligence and real life social establishments. Each candidate is given an equal opportunity to take a key role in the decision making process. Additional enhancements such as dynamism and memory retention capabilities boost the performance of DA. A comprehensive study is conducted with 21 benchmark functions to act as proof-of-concept and lay the groundwork for future works. The results so obtained, cement the competence of DA as it outperforms other algorithms in multiple unimodal and multimodal functions.
% diverse fields such as soft computing, functional optimization, data science and machine learning. These algorithms can be further sub-divided, with swarm intelligence, physics-inspired, social, evolutionary algorithms a few noteworthy. In this paper we present Democratic Algorithm (DA) , a social-construct based algorithm heavily inspired from hierarchy swarm intelligence and real life social establishments. Our proposal extends the existing methodology for hierarchical structures by framing experience into a viable component for future applications. A comprehensive study is conducted with 16 benchmark functions and real-life data to cement the competence of the algorithm with DA providing a markup of 2-7.4X of convergence rate. 
\end{abstract}

\begin{IEEEkeywords}
Optimization, Swarm intelligence, Democratic Algorithm, Memoization, Dynamic Structure
\end{IEEEkeywords}

\section{Introduction}

Optimization lies at the very core of majority of the problems ranging from machine learning to business planning. The level of importance awarded to optimization is due to the limited computational resources at hand. To compensate for the lack of resources, smarter algorithms are developed on an almost daily basis. These algorithms are capable of working efficiently in a constrained environment. 

\subsection{Multi-Objective Optimization Problem Definition}

As the name suggests, Multi-Objective Optimization Problems (MOOPs) require simultaneous solutions to multiple single-objective optimization problems each with it's own set of constraints. 

\begin{align}
\label{eqn:1}
Maximize/Minimize:f\textsubscript{m}(x)& &  m = 1,2\dots,M \\
constraints:g\textsubscript{j}(x) \ge 0& & j=1,2\dots,J \nonumber\\
h\textsubscript{k}(x) = 0& & k=1,2\dots,K \nonumber\\
x\textsubscript{i}\textsuperscript{L} \le x\textsubscript{i} \le x\textsubscript{i}\textsuperscript{U} && i = 1,2\dots,n.\nonumber 
\end{align}

Equation $\ref{eqn:1}$ describes a general MOOP consisting of $\textit{M}$ single-objective functions having $\textit{K}$ equality bounds and $\textit{J}$ inequality bounds \cite{chankong}. The $\textit{n}$ input vector components $\textit{x\textsubscript{i}}$ are also bounded within a lower $\textit{x\textsubscript{i}\textsuperscript{L}}$ and upper $\textit{x\textsubscript{i}\textsuperscript{U}}$ bound.

Usually MOOPs are solved by decomposing them into multiple single-objective optimization problems \cite{liu}. However, the striking difference in this method and directly solving a MOOP lies in the decision space. For a pure MOOP, the multi-dimensional decision space is accompanied with an objective space $\textit{Z}$. For each solution $\textit{x}$, there is a point in the objective space denoted by $\textit{z} = (\textit{z\textsubscript{1}}, \textit{z\textsubscript{2}}, \textit{z\textsubscript{3}}, \dots, \textit{z\textsubscript{M}})$. Hence pure MOOPs optimize a vector \cite{Deb} whereas multiple single-objective optimization problems optimize singular variables. 

\subsection{Dominance and Pareto Optimality}

Majority of MOOPs revolve around the idea of dominance as conflicts arise between multiple solutions. Consider a MOOP with $\textit{M}$ sub-optimzation problems leading to $\textit{N}$ solutions. For any solution $\textit{i} \in \textit{N}$ to dominate solution $\textit{j} \in \textit{N}$, there are two criteria which must be met.

\begin{itemize}
\item The solution $\textit{i}$ must be no worse than $\textit{j}$ in all sub-optimization problems $\textit{f\textsubscript{x}}$ for all $\textit{x} = 1,2 \dots, \textit{M}$
\item The solution $\textit{i}$ is strictly better than $\textit{j}$ in at least one sub-optimization problem $\textit{f\textsubscript{x}}$ for all $\textit{x} = 1,2 \dots, \textit{M}$
\end{itemize}

This concept, although intuitive, allows for a concrete definition of a solution being "better" than another and assists in searching for the non-dominated solutions. However, an interesting case appears between two solutions, when $\textit{i}$ is better than $\textit{j}$ in one sub-problem where $\textit{j}$ is better than $\textit{i}$ in another. After performing a pairwise comparison and eliminating all the singularly dominated solutions, we have a set of non-dominated solutions called the non-dominated set. Any solution inside this set, is better than any solution outside the set. 

When such a space constitutes the entire space of solutions, the set is called a Global Pareto-Optimal set. By introducing a neighboring constant which allows for some leverage, a Global Pareto-Optimal solution can be converted to a Local Pareto-Optimal solution. Therefore the initial MOOP is now transformed into a task of finding multiple Pareto-Optimal solutions with good diversity in decision variable values. The following section describes the various methods by which MOOPs can be solved. 


% \subsection{Orthodox Methods of Solving MOOPs}
% 
% The techniques developed in this section describe classical techniques which are based on mathematical and statistical reasoning. These algorithms are rather simplistic and quite intuitive. Some of the noteworthy techniques are discussed here:
% 
% \begin{itemize}
% 
% \item Weighting Sum Method: 
% 
% In this algorithm, the MOOP is decomposed into multiple singular problems and each problem is assigned a weight corresponding to it's respective importance to the global front. The weights must be quantified based on prior information and the singular objective functions must be normalized for proper setting of the weight vector \cite{arora}. Equation $\ref{eqn:2}$ decomposes the MOOP $F\textsubscript{m}(x)$ into $\textit{m}$ single-objective optimization problems and weight vector $w\textsubscript{m}$, subject to constraints mentioned in Equation $\ref{eqn:1}$.
% 
% \begin{equation}
% \label{eqn:2}
% Optimize:F\textsubscript{m}(x) =  \sum_{m=1}^{M}w\textsubscript{m}f\textsubscript{m}(x)
% \end{equation}
% 
% \begin{itemize}
% \item Advantages:
% \begin{enumerate}
% \item Simple and intuitive
% \end{enumerate}
% \item Disadvantages:
% \begin{enumerate}
% \item Required conversion of minmax problems into 1 type
% \item Difficulity in proper weight vector setting
% \end{enumerate}
% \end{itemize}
% 
% \item Weighted Metric Method:
% 
% This technique is a general extension of weighting sum method with a varient of combination of multiple objectives \cite{ryu}. Equation $\ref{eqn:3}$ represents this method where $\textit{l\textsubscript{p}}$ is the distance measure between candidate solution $\textit{x}$ and solution $\textit{z\textsuperscript{*}}$, parameter $\textit{p} \in [1,\infty]$. For $\textit{p}$ = 1, weighted metric decomposes into weighting sum method.
% 
% \begin{equation}
% \label{eqn:3}
% Optimize:l\textsubscript{p}(x) =  (\sum_{m=1}^{M}w\textsubscript{m}|f\textsubscript{m}(x) - z\textsubscript{m}\textsuperscript{*}|\textsuperscript{p})\textsuperscript{\sufr{1}{p}}
% \end{equation}
% 
% \begin{itemize}
% \item Advantages:
% \begin{enumerate}
% \item Simple yet generic distance metric
% \end{enumerate}
% \item Disadvantages:
% \begin{enumerate}
% \item Prerequistive knowledge of individual minima and maxima of each function is required
% \end{enumerate}
% \end{itemize}
% 
% \item Value Function Method:
% 
% In this method, the user must provide a value mapping function $\mathbb{U}:\mathbb{R\textsuperscript{M}} \rightarrow \mathbb{R}$ for all $\textit{M}$ functions. The optimization process is then reduced to Equation $\ref{eqn:4}$ \cite{sinha}, subject to the same constraints as Equation $\ref{eqn:1}$
% 
% \begin{equation}
% \label{eqn:4}
% Optimize: \mathbb{U}(f(x))
% \end{equation}
% 
% \begin{itemize}
% \item Advantages:
% \begin{enumerate}
% \item Ideal when prior information is available
% \end{enumerate}
% \item Disadvantages:
% \begin{enumerate}
% \item Problem of over-simplified value mapping function
% \end{enumerate}
% \end{itemize}
% 
% % This algorithm is one of the simplest way to solve a MOOP due to the intuitive nature, ease of use and elementary mathematical representation. However, there are a number of drawbacks associated with this algorithm such as unreliable mapping leading to difficulties in proper weight configuration and requirment of converting all minimization and maximization problems into 1 common type. 
% 
% \end{itemize}
% 
% Solving MOOPs using classical methods requires either prior information about the subproblems or assumptions for decomposition. These algorihtms have been put to use in multiple practical applications involving huge sets of internal parameters, which incur an overhead of optimal configuration setting. 
% 
\section{Solving MOOPs}

In this section, we provide a brief overview of methods to solve MOOPs and obtain Pareto-optimal solutions. Historically, these methods can be classified into classical and evolutionary techniques. Additional information about these techniques and their sub-classifications are provided in Table $\ref{tab1}$ and $\ref{tab2}$. Every algorithm is set back in one way or the other due to the No Free Lunch Theorem. Our goal in this paper is not create an algorithm which works perfectly for all problems, but to put forth a novel construct which mitigates the drawbacks of it's predecessors. 

\begin{table*}[!b]
\caption{\textsc{Classical Solving Methods}}
\label{tab1}
\centering
\scalebox{0.9}
{
\begin{tabular}{| c | c | c | c |}
\hline
\textbf{Subclass} & \textbf{Optimization Equation} & \textbf{Advantages} & \textbf{Disdvantages}\\
\hline
 &&&\\
 Weighting Method & $F\textsubscript{m}(x) =  \sum_{m=1}^{M}w\textsubscript{m}f\textsubscript{m}(x)$ & Simple, Intuitive & No constraints on weights, Not optimal for \\
 &&&nonconvex problems, Interactive\\
\hline
&&&\\
 $\epsilon$-Contrainst Method & $F\textsubscript{l}(x)$ w.r.t $F\textsubscript{m}(x) \leq \epsilon\textsubscript{m}$ & Ensures Pareto optimality and uniqueness,  & Not scalable, Range requirement,\\
   &  & Convexity is not necessary & Interactive \\
 &&&\\
 \hline 
 Neutral Compromise Solution & $\frac{F\textsubscript{m}(x) - ((z\textsubscript{i}\textsuperscript{*} + z\textsubscript{i}\textsuperscript{nad})/2)}{z\textsubscript{i}\textsuperscript{nad} - z\textsubscript{i}\textsuperscript{*}}$ & Approximate Solution, Rapid Process  & Weakly Pareto, Utopian and  \\
  &  &  & Nadir solution required \\
\hline
 Weighted Metrics & $(\sum_{m=1}^{M}w\textsubscript{m}|f\textsubscript{m}(x) - z\textsubscript{m}\textsuperscript{*}|\textsuperscript{p})\textsuperscript{\sufr{1}{p}}$ & Smaller feasible region & Nondifferentiable in some cases, \\
  &  &  & Convexity is required\\
 \hline
 &&&\\
 Value Function Method & $\mathbb{U}(F(x))$ & Excellent results when & Mandatory and Over simplified\\
   &  & mathematical representation is provided & mapping\\
 &&&\\
 \hline
\end{tabular}
}
\end{table*}

\begin{table*}[!b]
\caption{\textsc{Evolutionary Solving Methods}}
\label{tab2}
\centering

{
\begin{tabular}{| c | c | c |}
\hline
\textbf{Subclass}&\textbf{Advantages}&\textbf{Disadvantage}\\
\hline
Preference relation&Dominant Pareto guarentee&Required reference point\\
\hline
Light Beam Method&Optimal distance crowding&Reference direction threshold\\
\hline
Imprecise value function&Solution based ranking&Dominant solutions\\
\hline
Biased Crowding&Desired trade-off&Crowding of solutions\\
\hline
\end{tabular}
}
\end{table*}

A common drawback pattern encountered in the listed techniques is dominance factor. Light Beam method works towards being independent from this factor by leveraging a prior knowledge on the reference direction. Whereas Imprecision value function method takes in a ranking system, but created dominant solutions. 

% 
% \subsection{Quantified problems in Classical Computation}
% 
% The algorithms described in the preceeding section can be classified as either direct search or gradient based search techniques \cite{arnold}. Direct search algorithms user described constriants are utilized in their raw format to guide the solution. Gradient based search techniques use derivatives of the objective function and constraints to guide the solution. However, both these techniques encouter similar problems as described:
% 
% \begin{itemize}
% \item Result is dependent on selection of initial state 
% \item Tendency to get stuck in local optima
% \item Lack of genralization due to dependence on problem statement
% \item Requirement of mathemtical representation 
% \item Inefficient when it comes to non-differentiable or discontinous problems
% \item Lack of parallelization in majority of the algorithms
% \item Time incurred is high due to single search guidance system
% \end{itemize}
% 
% These problems resulted in the development of new fields in Computational Intelligence, namely Evolutionary Algorithms (EA) \cite{vikhar} and Swarm Intelligence (SI) \cite{swarm}. The main motivation for the development of these algorithms is to alleviate the hurdles faced by classical algorithms. 
% 
% \subsection{Swarm Intelligence to the Rescue}
% 
% SI proposes emulating naturally occuring groups and their behaviour for optimal functioning. $\textit{Swarm}$ refers to a group of disorganized individuals working towards the common goal of finding the global optimum. When viewed seperatley, these individuals are particularly ineffective. However when properly instructed, these individuals transform into a centralized, collective and self-organized entity. When deployed accurately, a dynamic search pattern, better than random search, appears. This intelligence and self-organizing technique is called Swarm intelligence and is depicted in Algorithm $\ref{alg:SI}$.
% 

% 
% \subsection{Genetic Modifiers}
% 
% Under the umbrella of EA, Genetic Algorithms (GA) \cite{man} has emerged as one of the most popular search and optimization techniques. The core of GA lies in the feedback process, which updates the candidate solutions in accordance with 3 main sub-processes. Figure $\ref{ga}$ summarizes the entire process of GA.
% 
% \begin{itemize}
% \item Selection: This step involves selecting the candidates having the best fitness score. The method used for DA is the rank-based selection \cite{abdul} in which the probability of selection of a chromosome is directly related to the corresponding fitness value. 
% \item Crossover: The characteristics of the parents selected at the selection stage are intermixed to generate better candidates in the next generation. BLX or Blend Crossover \cite{kita} technique was utilized to have the optimal feature selection. 
% \item Mutation: As an add-on to the generational transition, random changes are added to add diversity and possibly improve the candidates. Inversion Mutation \cite{im} was applied to introduce a sense of randomness into the process.
% \end{itemize}
% 
% \begin{figure}[!b]
% \centering
% \includegraphics[height=7.93cm]{ga.png}
% \caption{Genetic Algorithm}
% \label{ga}
% \end{figure}

\section{Democratic Algorithm (DA)}

In this section we present a novel social-construct based algorithm heavily inspired from swarm intelligence and real life social establishments which provides a solution to the conundrum presented in the previous section. DA deploys multiple candidates in a dynamically structured format into the solution landscape instead of a static master-follower format. The increased competition results in increased desire for current candidates to find the Pareto optimal. 

\subsection{Inspiration}
The term "Democracy" was coined in Athens, Greece and literally translates to "Strength of the People". The 2 main characteristics borrowed from the social ideology for this algorithm are as follows.

\begin{itemize}
\item Equal opportunity for any candidate to ascend and claim the global decision making spot
\item Proportional influence on the decision making process.

\end{itemize}

We follow an extended social hierarchical structure to incorporate some fundamentals of SI into this algorithm. The initial population set is divided into five departments: A, B, C, D, E and are arranged as shown in figure $\ref{struct}$.

\begin{figure}[!t]
\centering
\includegraphics[height=5cm]{struct.png}
\caption{Structure of DA}
\label{struct}
\end{figure}

The division of departments is based on the relative scores obtained against the set fitness function. Candidates belonging to the higher departments dictate the overall global optima searching process whilst guiding and taking advice from the lower departments. Following initialization, there are two main seasons involved in this algorithm.
\begin{itemize}
\item Guiding Season
\item Voting Season
\end{itemize}

In the following subsections, models of the social hierarchy and the seasons are explained, followed by outlining of the entire algorithm.  

\subsection{Guiding Season}

This phase has the sole purpose of finding the optimal solution. Candidates belonging to the highest department are responsible for finding the solution. The other candidates act as advisers which help maintain the social structure and prevent the search process from falling into local optima. In order to introduce a dynamic factor the search process, the solutions obtained by the top departments are continously stored in a table for any future reference. The updation of the current position is done based a a weighted sum of the current position of all the departments. Based on the difference between the solution provided and the true solution, the top department's reqard score is either incremented or decremented by 1. The algorithm is depicted in Algorithm $\ref{alg:gs}$.

\begin{algorithm}[!t]
\footnotesize
\caption{Guiding Season}
\label{alg:gs}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Population size $\textit{n}$, Set of stopping criteria $\lambda\textsubscript{i}$, fitness function $\textit{f}$
\STATE Create candidate solutions $\textit{S}$ of size $\textit{n}$ 
\FOR{Each candidate $\textit{s\textsubscript{i}}$ in $\textit{S}$}
\STATE Apply $\textit{f}$ on $\textit{s\textsubscript{i}}$
\ENDFOR
\STATE Based on selected architecture, establish group dynamics
\WHILE{Any of $\lambda\textsubscript{i}$ are not met}
\IF{Predicted Fitness is acceptable}
\STATE Apply algorithms related to the selection phase
\ELSE
\STATE Apply algorithms related to the variation phase
\ENDIF
\ENDWHILE
\STATE Predicted solution corresponds to global optimum
\end{algorithmic}
\end{algorithm}

\subsection{Voting Season}

After a set time period $\textit{T}$ if the total reward score does not exceed a threshold $\lambda$ then the top department is replaced by the one just below it. If $\lambda$ is exceeded, then the next problem is loaded with the current configuration.

The entire process of the voting season is displayed in Algorithm $\ref{alg:da}$.

\begin{algorithm}[!t]
\footnotesize
\caption{Voting Season}
\label{alg:da}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Population size $\textit{n}$, random vector set $\vec{r\textsubscript{1,j}}$, $\vec{r\textsubscript{2,j}} \in$ [0,1], weight vector $\vec{w}$, initial estimate of global optimum $\textit{X\textsubscript{g}}$, time period $\textit{T}$, threshold $\lambda$, fitness function $\textit{f}$, coefficient vector sets $\vec{A\textsubscript{j}}$, $\vec{C\textsubscript{j}}$ and $\vec{a\textsubscript{j}}$
\STATE Set $\textit{t}$ = 0
\STATE Initialize vector set $\vec{A\textsubscript{j}}$ = 2$\vec{a} \cdot \vec{r\textsubscript{1}}$ - $\vec{a}$
\STATE Initialize vector set $\vec{C\textsubscript{j}}$ = 2$\vec{r\textsubscript{2}}$
% and $\vec{a\textsubscript{j}}$
\IF {Table $\textit{H}$ exists with current function problem}
\STATE Refer to table $\textit{H}$ for solution
\ELSE
\STATE Create table $\textit{H}$ mapping input to corresponding output and apply memoization
\STATE Create table $\textit{R}$ to store the performance of each department
\FOR{i $\in$ [1,n]}  
\STATE Generate population results $\textit{X\textsubscript{i}(t)}$ at instance $\textit{t}$
\STATE Evaluate each individual against the fitness function
\ENDFOR
\STATE Assign A, B, C, D, E departments as per the score against the fitness function. 
\STATE Evaluate $\vec{D\textsubscript{j}} = |\vec{C} \cdot \vec{X\textsubscript{g}}(t) - \vec{X\textsubscript{j}}(t)|$
\WHILE{t $<$ T}
\FOR{Each individual $\textit{X\textsubscript{i,j}(t)}$ in each department $\textit{j}$}
\STATE Update $\textit{X\textsubscript{i,j}(t)}$ := $\textit{X\textsubscript{j}(t)}$ - $\vec{A}$($\vec{D\textsubscript{j}}$)
\STATE $\textit{X\textsubscript{i,j}(t+1)}$ = $\frac{\vec{w} \cdot \textit{X\textsubscript{i,j}(t)}}{5}$
\ENDFOR
\STATE Check fitness of $\textit{X\textsubscript{top}}$ against $\textit{f}$
\IF{Fitness score is acceptable}
\STATE Increase score of $\textit{X\textsubscript{top}}$ in $\textit{R\textsubscript{top}}$ by 1
\ELSE
\STATE Decrease score of $\textit{X\textsubscript{top}}$ in $\textit{R\textsubscript{top}}$ by 1
\ENDIF
\ENDWHILE
\STATE At $\textit{t}$ = $\textit{T}$, check score of top department
\IF{$\textit{score\textsubscript{top}} \geq \lambda$}
\STATE Continue
\ELSE
\STATE Replace $\textit{X\textsubscript{top}}$ with $\textit{X\textsubscript{top-1}}$
\ENDIF
\STATE Update $\vec{a}$ := 2($\frac{T-t}{T}$)
\STATE Update $\vec{A}$ and $\vec{C}$ accordingly
\STATE $\textit{X\textsubscript{top}}$ represent required set of optimal solutions
\STATE Add corresponding function and solution to $\textit{H}$ for future reference
\ENDIF
\end{algorithmic}
\end{algorithm}

\subsection{Key points}

From a mathematical point of view, both the structure and the search processes evolve over time with feedback. For each search, a lookup is conducted by candidate $\textit{c}$ in table $\textit{H}$. If not found, a solution $\textit{x\textsubscript{0}}$ is assumed as the initial point and the search of optimum solution $\textit{x\textsubscript{1}}$. To escape the local optimum, a penalty is added to the fitness function $\textit{f}$ such that the resulting fitness function h allows local search to escape. A new local search is started from $\textit{x\textsubscript{1}}$ using the modified fitness function $\textit{f}$. Search continues until a termination criterion is met. Based on the representation, the following observations can be made:
\begin{itemize}
\item The updation process occurs at an individual and departmental level to save the best solutions obtained so far
\item The parameters $\vec{A}$ and $\vec{C}$ assist the solutions to have higher dimensionality
\item Due to the dual updation and introduction of a memory element, the problems functions will saturate at a middle level department
\item The voting season provides weighted rights to each candidate in each department. The weights are assigned based on the individual's fitness which in turn is dependent on their department's position 
\item As the department rank increases, the number of individual candidate in the department decreases to promote elitism. This would ensure survival of the best solutions in future problems. 
\item As the department rank decreases, the number of individual candidate in the department increase to promote diversity. This would open up new avenues to explore and possibly increase chances of finding the gobal optimum.  
\item The increased number of parameters requires fine tunning which can be automated
\end{itemize}

To sum up, DA starts with generating and evaluating a set of candidate solutions. The solutions are grouped according to their relative goodness of fit. The top candidates are responsible for finding the optimum solution while the other candidates are required to maintain the hierarchy, provide valuable input to the leaders and contest when the results begin deteriorating. When the top department does not function as per requirement, the lower departments replace it. A memory component is introduced in the form of a table which maps the previously encountered inputs to their corresponding outputs. 

\section{Results and Discussion}

In this section the DA algorithm is benchmarked against 18 standard minimization functions. These functions are described in Table $\ref{tab:1}$. The DA was iterated 20 times on each of these functions and the results were compared against other popular SI algorithms such as Particle Swarm Optimization (PSO) \cite{pso}, Grey Wolf Optimization (GWO) \cite{gwo}, Multiverse Optimization (MVO)\cite{mvo} and Cuckoo Search (CS) \cite{cs}. The metric based results such as mean and standard deviation is listed in Table $\ref{tab:2}$. The experiment was set up on a 64-bit Machine with Ubuntu 20.04, Intel® CoreTM i5-7200U CPU @ 2.50GHz × 4, with a GeForce 940MX/PCle/SSE2 graphic card.

Based on the results, DA provides ambitious results on the becnhmark functions \cite{bf}. DA outperforms the other algorithms in F2, F8, F15 and F18. The selective performance boosts could be attributed to the optimal voting season. In certain cases the top departments would have saturated and the replacement process might have been ineffective. As it is the case with any algorithm, global optimum search can never be guarenteed.  


\begin{table*}[!t]
\caption{\textsc{Benchmark Functions}}
\label{tab:1}
\centering
\scalebox{0.9}
{
\begin{tabular}{| >{\arraybackslash}m{0.88in} | c | c | >{\arraybackslash}m{0.4in} | c | >{\arraybackslash}m{1in} | c |}
\hline
Function & ID & Formula & Modality & Range & Minimum Value & Department \\
\hline
Matyas & F1 & $0.26(x\textsubscript{2} + y\textsubscript{2}) - 0.48xy$ & Uni & [-10,10] & 0 at $x\textsuperscript{*}$ = (0,0) & A\\
Booth & F2 & $(x + 2y - 7)\textsuperscript{2} + (2x + y - 5)\textsuperscript{2}$ & Uni & [-10,10] & 0 at $x\textsuperscript{*}$ = (1,3) & A\\
Bohachevsky & F3 & $x\textsuperscript{2} + 2y\textsuperscript{2} -0.3cos(3\pi x)-0.4cos(4\pi y)+0.7$ & Uni & [-100,100] & 0 at $x\textsuperscript{*}$ = (0,0) & A\\
Gramacy and Lee & F4 & $\frac{sin(10\pi x)}{2x} + (x-1)\textsuperscript{4}$ & Uni & [-0.5,2.5] & -0.869 at $x\textsuperscript{*}$ = (0.5485) & A\\
Leon & F5 & $100(y-x\textsuperscript{3})\textsuperscript{2}$ + $(1-x)\textsuperscript{2}$ & Uni & [-10,10] & 0 at $x\textsuperscript{*}$ = (1,1) & B\\
Ackley & F6 & $-20 exp(-0.2 \sqrt{\frac{1}{n} \sum_{i=1}^n x_i^2}) - exp(\frac{1}{n} \sum_{i=1}^n cos(2\pi x_i)) + 20 + e$ & Multi & [-32,32] & 0 at $x\textsuperscript{*}$ = (0,0) & A\\
Bartels & F7 & $|x\textsuperscript{2} + y\textsuperscript{2} + xy| + |sin(x)| + |cos(y)|$ & Multi & [-500,500], [-500,500] & 1 at $x\textsuperscript{*}$ = (0,0) & A\\
Branin & F8 & $a(x\textsubscript{2} - bx\textsubscript{1}\textsuperscript{2} + cx\textsubscript{1} - r)\textsuperscript{2}$ + $s(1-t)cos(x\textsubscript{1})$ + s & Multi & [-5,10], [0,15] & 0.397887 at $x\textsuperscript{*}$ = (-$\pi$, 12.275) & B\\
Egg Crate & F9 & $x\textsuperscript{2}$ + $y\textsuperscript{2}$ + $25(sin\textsuperscript{2}(x) + cos\textsuperscript{2}(x))$ & Multi & [-5,5] & 0 at $x\textsuperscript{*}$ = (0,0) & B\\
Qing & F10 & $\sum_{i=1}^{n}(x^2-i)^2$ & Multi & [-500,500] & 0 at $x\textsuperscript{*}$ = ($\pm\sqrt{i}$) & A\\
Rastrigin & F11 & $10n + \sum_{i=1}^{n}(x_i^2 - 10cos(2\pi x_i))$ & Multi & [-5.12,5.12], [-500,500] & 0 at $x\textsuperscript{*}$ = (0,0) & C\\
Rosenbrock & F12 & $\sum_{i=1}^{n}[b (x_{i+1} - x_i^2)^ 2 + (a - x_i)^2]$ & Multi & [-5.12,5.12], [-5,10] & 0 at $x\textsuperscript{*}$ = (1) & C\\
Bird & F13 & $sin(x)e\textsuperscript{(1-cos(y))^2}+cos(y)e\textsuperscript{(1-sin(x))^2}+(x-y)\textsubscript{2}$ & Multi & [-2$\pi$, 2$\pi$] & -106.76 at $x\textsuperscript{*}$ = (4.70104,3.1529), (-1.58214,-3.1302) & A\\
Powell Sum & F14 & $\sum_{i=1}^{n}|x_i|^{i+1}$ & Multi & [-1,1] & 0 at $x\textsuperscript{*}$ = 0 & A\\
Schaffer & F15 & $0.5 + \frac{sin\textsuperscript{2}(x\textsuperscript{2}-y\textsuperscript{2})-0.5}{(1+0.001(x\textsuperscript{2}+x\textsuperscript{2}))\textsuperscript{2}}$ & Multi & [-100,100] & 0 at $x\textsuperscript{*}$ = (0,0) & B\\
Shubert & F16 & $\prod_{i=1}^{n}{\left(\sum_{j=1}^5{ cos((j+1)x_i+j)}\right)}$ & Multi & [-10,10] & -186.7309  & A\\
Happy Cat & F17 & $\left[\left(||\textbf{x}||^2 - n\right)^2\right]^\alpha + \frac{1}{n}\left(\frac{1}{2}||\textbf{x}||^2+\sum_{i=1}^{n}x_i\right)+\frac{1}{2}$ & Multi & [-2,2] & 0 at $x\textsuperscript{*}$ = (-1)  & A\\
Alpine & F18 & $\prod_{i=1}^{n}\sqrt{x_i}sin(x_i)$ & Multi & [0,10] & 2.808 at $x\textsuperscript{*}$ = (7.917)  & B\\
\hline
\end{tabular}
}
\end{table*}

\begin{table*}[t]
\caption{\textsc{Benchmark Results}}
\label{tab:2}
\centering
{
\begin{tabular}{| c | c  c | c  c | c  c | c  c | c  c |}
\hline
{\textbf{Function}}&{\textbf{PSO}}&{}&{\textbf{GWO}}&{}&{\textbf{MVO}}&{}&{\textbf{CS}}&{}&{\textbf{DA}}&{}\\
\hline
{}&{\textbf{Mean}}&{\textbf{Std}}&{\textbf{Mean}}&{\textbf{Std}}&{\textbf{Mean}}&{\textbf{Std}}&{\textbf{Mean}}&{\textbf{Std}}&{\textbf{Mean}}&{\textbf{Std}}\\
\hline
{F1}&{1.339E-08}&{6.224E-04}&{2.411E-06}&{4.968E-05}&{5.221E-06}&{8.235E-08}&{9.711E-06}&{4.397E-07}&{8.712E-06}&{5.113E-05}\\
{F2}&{4.859E-10}&{0.5287}&{6.276E-09}&{5.171E-06}&{6.181E-07}&{0.8412}&{9.551E-09}&{3.854E-07}&{7.622E-11}&{2.625E-06}\\
{F3}&{8.156E-13}&{1.712E-07}&{3.897E-11}&{8.422E-07}&{9.252E-15}&{4.976E-06}&{2.416E-12}&{8.256E-07}&{1.823E-15}&{7.424E-05}\\
{F4}&{-0.7624}&{3.153}&{-0.6887}&{18.542}&{-0.8219}&{12.843}&{-0.7943}&{28.954}&{-0.8149}&{21.148}\\
{F5}&{0}&{0.0133}&{5.18E-24}&{0.0023}&{4.81E-20}&{0.0141}&{5.73E-27}&{0.0072}&{8.19E-29}&{0.0058}\\
{F6}&{5.177E-16}&{0.0251}&{1.415E-11}&{0.0595}&{2.478E-38}&{0.0224}&{7.714E-24}&{0.0119}&{4.082E-32}&{0.0084}\\
{F7}&{0.9521}&{0.0253}&{0.8445}&{0.0081}&{0.5122}&{0.0047}&{0.9154}&{0.0005}&{0.9204}&{0.0007}\\
{F8}&{0.3181}&{0.0012}&{0.2118}&{0.0084}&{0.3518}&{0.0152}&{0.3154}&{0.0002}&{0.3751}&{0.0084}\\
{F9}&{1.145E-08}&{5.152E-06}&{1.845E-09}&{5.691E-05}&{4.845E-08}&{3.452E-06}&{7.183E-08}&{6.541E-07}&{2.495E-09}&{5.88E-06}\\
{F10}&{5.483E-19}&{4.465E-08}&{7.842E-18}&{9.421E-05}&{7.515E-25}&{4.118E-05}&{9.152E-19}&{4.783E-05}&{1.215E-19}&{2.512E-06}\\
{F11}&{6.152E-20}&{0.0512}&{4.125E-38}&{0.0001}&{2.489E-28}&{0.0915}&{4.852E-26}&{0.0185}&{4.845E-29}&{0.0943}\\
{F12}&{0.0051}&{0.0218}&{0.0009}&{0.3512}&{0.0205}&{0.0945}&{0.0006}&{0.1534}&{0.001}&{0.0035}\\
{F13}&{-100.15}&{0.0029}&{-98.153}&{0.0675}&{-63.156}&{0.0005}&{-156.51}&{0.0266}&{-94.845}&{0.432}\\
{F14}&{0.0241}&{0.0008}&{0.0099}&{0.0021}&{0.0007}&{0.0315}&{0.0842}&{0.0239}&{0.0579}&{0.0679}\\
{F15}&{5.194E-16}&{8.495E-05}&{7.162E-20}&{2.846E-05}&{7.899E-E11}&{3.793E-05}&{6.977E-19}&{8.297E-05}&{3.842E-22}&{2.655E-07}\\
{F16}&{-215.15}&{0.0021}&{-288.31}&{0.0842}&{-160.249}&{0.3512}&{-206.49}&{0.0002}&{-153.123}&{0.0004}\\
{F17}&{0.0021}&{0.1532}&{0.0044}&{0.2953}&{0.0531}&{0.0212}&{0.0094}&{0.0121}&{0.0076}&{0.4683}\\
{F18}&{2.5321}&{0.0515}&{1.2854}&{0.7542}&{1.9458}&{0.1523}&{2.0057}&{0.0021}&{2.6185}&{0.0218}\\
\hline
\end{tabular}
}
\end{table*}

The plots for F1, F2, F3, F6, F15 and F17 have been shown in Figures $\ref{figur:1}$, $\ref{figur:2}$, $\ref{figur:3}$, $\ref{figur:4}$, $\ref{figur:5}$ and $\ref{figur:6}$. For these functions, the initial top department was capable of producing acceptable results. Due to the acceptance, the voting season never arrived and the process terminated. \\
% 
% \begin{figure}[!t]
% \begin{subfigure}{.275\textwidth}
%   \centering
%   \includegraphics[width=.8\linewidth]{akleya.png}
%   \caption{Ackley}
%   \label{fig:sfig1}
% \end{subfigure}%
% \begin{subfigure}{.275\textwidth}
%   \centering
%   \includegraphics[width=.8\linewidth]{bartelsa.png}
%   \caption{Bartels}
%   \label{fig:sfig2}
% \end{subfigure}
% \caption{Departmant A Dominance}
% \label{fig:fig}
% \end{figure}
% 
The plots for F8, F10 and F18 have been shown in Figures $\ref{figur:7}$, $\ref{figur:8}$, $\ref{figur:9}$, $\ref{figur:10}$, $\ref{figur:11}$ and $\ref{figur:12}$. For these two functions, the initial top department was inapable of producing acceptable results. In the following voting season the total reward did not exceed $\lambda$ and hence B dominance started. 

The plots for F11 and F12 have been shown in Figures $\ref{figur:13}$, $\ref{figur:14}$, $\ref{figur:15}$, $\ref{figur:16}$, $\ref{figur:17}$ and $\ref{figur:18}$. For these two functions, both, the initial top department and the subsequent leaders, were incapable of producing acceptable results. Due to the acceptance, the top departments were voted out after two voting seasons. Department C is promoted and it performs better due to the improved structure and the experience accumulated by the previous top departments.\\
% 
% \begin{figure}[!t]
% \subfloat[Branin-A]{\includegraphics[width = 2in]{branina.png}} 
% \subfloat[Branin-B]{\includegraphics[width = 1.9in]{braninb.png}}\\
% \caption{}
% \label{fig:sfig3}
% \end{figure}
% \begin{figure}[!t]
% \begin{subfigure}{.275\textwidth}
%   \centering
%   \includegraphics[width=.8\linewidth]{egga.png}
%   \caption{Egg Crate-A}
%   \label{fig:sfig4}
% \end{subfigure}%
% \begin{subfigure}{.275\textwidth}
%   \centering
%   \includegraphics[width=.8\linewidth]{eggb.png}
%   \caption{Egg Crate-B}
%   \label{fig:sfig5}
% \end{subfigure}
% \caption{Departmant B Dominance}
% \label{fig:sfig6}
% \end{figure}
% 
% The plots for F11 and F12 have been shown in Figures $\ref{fig:sfig7}$ and $\ref{fig:sfig8}$. For these two functions, both, the initial top department and the subsequent leaders, were incapable of producing acceptable results. Due to the acceptance, the top departments were voted out after two voting seasons. Department C is promoted and it performs better due to the improved structure and the experience accumulated by the previous top departments.
% 
% \begin{figure}[!t]
% \subfloat[Rastrigin-A]{\includegraphics[width = 1.25in]{rastrigina.png}} 
% \subfloat[Rastrigin-B]{\includegraphics[width = 1.25in]{rastriginb.png}}
% \subfloat[Rastrigin-C]{\includegraphics[width = 1.25in]{rastriginc.png}}\\
% \caption{}
% \label{fig:sfig7}
% \end{figure}
% 
% \begin{figure}[!t]
% \subfloat[Rosenbrock-A]{\includegraphics[width = 1.25in]{rosenbrocka.png}} 
% \subfloat[Rosenbrock-B]{\includegraphics[width = 1.25in]{rosenbrockb.png}}
% \subfloat[Rosenbrock-C]{\includegraphics[width = 1.25in]{rosenbrockc.png}}\\
% \caption{Department C Dominance}
% \label{fig:sfig8}
% \end{figure}

\begin{figure}[htp]
  \centering
  \label{figur}\caption{Department A Dominant}

  \subfloat[Ackley]{\label{figur:1}\includegraphics[width=50mm]{ackley.png}}
  \subfloat[Bohachevskyn]{\label{figur:2}\includegraphics[width=50mm]{boha.png}}
  \\
  \subfloat[Booth]{\label{figur:3}\includegraphics[width=50mm]{booth.png}}
  \subfloat[Matyas]{\label{figur:4}\includegraphics[width=50mm]{matyas.png}}
  \\
  \subfloat[Schaffern]{\label{figur:5}\includegraphics[width=50mm]{schaffern.png}}
  \subfloat[Happy Cat]{\label{figur:6}\includegraphics[width=43.5mm]{happycat.png}}
\end{figure}

\begin{figure}[htp]
  \centering
  \label{figur}\caption{Department B Dominant}

  \subfloat[Alpine-A]{\label{figur:7}\includegraphics[width=45mm]{alpinea.png}}
  \subfloat[Alpine-B]{\label{figur:8}\includegraphics[width=45mm]{alpineb.png}}
  \\
  \subfloat[Qing-A]{\label{figur:9}\includegraphics[width=37mm]{qinga.png}}
  \subfloat[Qing-B]{\label{figur:10}\includegraphics[width=37mm]{qingb.png}}
  \\
  \subfloat[Branin-A]{\label{figur:11}\includegraphics[width=45mm]{branina.png}}
  \subfloat[Branin-B]{\label{figur:12}\includegraphics[width=45mm]{braninb.png}}
\end{figure}

\begin{figure*}[htp]
  \centering
  \label{figur}\caption{Department C Dominant}

  \subfloat[Alpine-A]{\label{figur:13}\includegraphics[width=45mm]{rastrigina.png}}
  \subfloat[Alpine-B]{\label{figur:14}\includegraphics[width=45mm]{rastriginb.png}}
  \subfloat[Alpine-B]{\label{figur:15}\includegraphics[width=45mm]{rastriginc.png}}
  \\
  \subfloat[Qing-A]{\label{figur:16}\includegraphics[width=45mm]{rosenbrocka.png}}
  \subfloat[Qing-B]{\label{figur:17}\includegraphics[width=45mm]{rosenbrockb.png}}
  \subfloat[Alpine-B]{\label{figur:18}\includegraphics[width=45mm]{rosenbrockc.png}}
  \\
\end{figure*}

For any future extensions on this work, the follwing areas can be explored:

\begin{itemize}
\item Improved updation rules for the coefficient vectors.
\item Increase the number of parameters for improved model performance.
\item Generate a framework to decide on the number of departments.
\item Decrease the complexity of the algorithm by improving the table updation.
\item Introduction of concurrency.
\end{itemize}
% This document is a model and instructions for \LaTeX.
% Please observe the conference page limits. 
% 
% \section{Ease of Use}
% 
% \subsection{Maintaining the Integrity of the Specifications}
% 
% The IEEEtran class file is used to format your paper and style the text. All margins, 
% column widths, line spaces, and text fonts are prescribed; please do not 
% alter them. You may note peculiarities. For example, the head margin
% measures proportionately more than is customary. This measurement 
% and others are deliberate, using specifications that anticipate your paper 
% as one part of the entire proceedings, and not as an independent document. 
% Please do not revise any of the current designations.
% 
% \section{Prepare Your Paper Before Styling}
% Before you begin to format your paper, first write and save the content as a 
% separate text file. Complete all content and organizational editing before 
% formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on 
% proofreading, spelling and grammar.
% 
% Keep your text and graphic files separate until after the text has been 
% formatted and styled. Do not number text heads---{\LaTeX} will do that 
% for you.
% 
% \subsection{Abbreviations and Acronyms}\label{AA}
% Define abbreviations and acronyms the first time they are used in the text, 
% even after they have been defined in the abstract. Abbreviations such as 
% IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
% abbreviations in the title or heads unless they are unavoidable.
% 
% \subsection{Units}
% \begin{itemize}
% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
% \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
% \end{itemize}
% 
% \subsection{Equations}
% Number equations consecutively. To make your 
% equations more compact, you may use the solidus (~/~), the exp function, or 
% appropriate exponents. Italicize Roman symbols for quantities and variables, 
% but not Greek symbols. Use a long dash rather than a hyphen for a minus 
% sign. Punctuate equations with commas or periods when they are part of a 
% sentence, as in:
% \begin{equation}
% a+b=\gamma\label{eq}
% \end{equation}
% 
% Be sure that the 
% symbols in your equation have been defined before or immediately following 
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''
% 
% \subsection{\LaTeX-Specific Advice}
% 
% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.
% 
% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.
% 
% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.
% 
% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files. 
% 
% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3. 
% 
% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.
% 
% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.
% 
% \subsection{Some Common Mistakes}\label{SCM}
% \begin{itemize}
% \item The word ``data'' is plural, not singular.
% \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
% \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
% \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
% \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
% \item Do not confuse ``imply'' and ``infer''.
% \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
% \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
% \end{itemize}
% An excellent style manual for science writers is \cite{b7}.
% 
% \subsection{Authors and Affiliations}
% \textbf{The class file is designed for, but not limited to, six authors.} A 
% minimum of one author is required for all conference articles. Author names 
% should be listed starting from left to right and then moving down to the 
% next line. This is the author sequence that will be used in future citations 
% and by indexing services. Names should not be listed in columns nor group by 
% affiliation. Please keep your affiliations as succinct as possible (for 
% example, do not differentiate among departments of the same organization).
% 
% \subsection{Identify the Headings}
% Headings, or heads, are organizational devices that guide the reader through 
% your paper. There are two types: component heads and text heads.
% 
% Component heads identify the different components of your paper and are not 
% topically subordinate to each other. Examples include Acknowledgments and 
% References and, for these, the correct style to use is ``Heading 5''. Use 
% ``figure caption'' for your Figure captions, and ``table head'' for your 
% table title. Run-in heads, such as ``Abstract'', will require you to apply a 
% style (in this case, italic) in addition to the style provided by the drop 
% down menu to differentiate the head from the text.
% 
% Text heads organize the topics on a relational, hierarchical basis. For 
% example, the paper title is the primary text head because all subsequent 
% material relates and elaborates on this one topic. If there are two or more 
% sub-topics, the next level head (uppercase Roman numerals) should be used 
% and, conversely, if there are not at least two sub-topics, then no subheads 
% should be introduced.
% 
% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.
% 
% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}
% 
% % \begin{figure}[htbp]
% % \centerline{\includegraphics{fig1.png}}
% % \caption{Example of a figure caption.}
% % \label{fig}
% % \end{figure}
% 
% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
% rather than symbols or abbreviations when writing Figure axis labels to 
% avoid confusing the reader. As an example, write the quantity 
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
% units in the label, present them within parentheses. Do not label axes only 
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
% quantities and units. For example, write ``Temperature (K)'', not 
% ``Temperature/K''.
% 
% \section*{Acknowledgment}
% 
% The preferred spelling of the word ``acknowledgment'' in America is without 
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
% acknowledgments in the unnumbered footnote on the first page.
% 
% \section*{References}
% 
% Please number citations consecutively within brackets \cite{b1}. The 
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''
% 
% Number footnotes separately in superscripts. Place the actual footnote at 
% the bottom of the column in which it was cited. Do not put footnotes in the 
% abstract or reference list. Use letters for table footnotes.
% 
% Unless there are six authors or more give all authors' names; do not use 
% ``et al.''. Papers that have not been published, even if they have been 
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
% that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
% Capitalize only the first word in a paper title, except for proper nouns and 
% element symbols.
% 
% For papers published in translation journals, please give the English 
% citation first, followed by the original foreign-language citation \cite{b6}.
% 

\begin{thebibliography}{00}
\bibitem{chankong} Chankong V., Haimes Y, Thadathil J., Zionts S. (1985), Multiple Criteria Optimization: A State of the Art Review, Decision Making with Multiple Objectives, Lecture Notes in Economics and Mathematical Systems 242, Edited by Y.Y. Haimes, V. Chankong, SpringerVerlag, 36.

\bibitem{liu} H. Liu, F. Gu and Q. Zhang, "Decomposition of a Multiobjective Optimization Problem Into a Number of Simple Multiobjective Subproblems," in IEEE Transactions on Evolutionary Computation, vol. 18, no. 3, pp. 450-455, June 2014, doi: 10.1109/TEVC.2013.2281533. 

\bibitem{Deb} K. Deb, K. Miettinen and S. Chaudhuri, "Toward an Estimation of Nadir Objective Vector Using a Hybrid of Evolutionary and Local Search Approaches," in IEEE Transactions on Evolutionary Computation, vol. 14, no. 6, pp. 821-841, Dec. 2010, doi: 10.1109/TEVC.2010.2041667.

\bibitem{arora} Marler, R.T., Arora, J.S. The weighted sum method for multi-objective optimization: new insights. Struct Multidisc Optim 41, 853–862 (2010). https://doi.org/10.1007/s00158-009-0460-7

\bibitem{ryu} N. Ryu, W. S. Song, Y. Jung and S. Min, "Multi-Objective Topology Optimization of a Magnetic Actuator Using an Adaptive Weight and Tunneling Method," in IEEE Transactions on Magnetics, vol. 55, no. 6, pp. 1-4, June 2019, Art no. 7202504, doi: 10.1109/TMAG.2019.2899893.

\bibitem{sinha} A. Sinha, K. Deb, P. Korhonen and J. Wallenius, "Progressively interactive evolutionary multi-objective optimization method using generalized polynomial value functions," IEEE Congress on Evolutionary Computation, Barcelona, 2010, pp. 1-8, doi: 10.1109/CEC.2010.5586278.

\bibitem{arnold} D. V. Arnold and R. Salomon, "Evolutionary Gradient Search Revisited," in IEEE Transactions on Evolutionary Computation, vol. 11, no. 4, pp. 480-495, Aug. 2007, doi: 10.1109/TEVC.2006.882427.

\bibitem{vikhar} P. A. Vikhar, "Evolutionary algorithms: A critical review and its future prospects," 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC), Jalgaon, 2016, pp. 261-265, doi: 10.1109/ICGTSPICC.2016.7955308.

\bibitem{swarm} Yan-fei Zhu and Xiong-min Tang, "Overview of swarm intelligence," 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), Taiyuan, 2010, pp. V9-400-V9-403, doi: 10.1109/ICCASM.2010.5623005.

\bibitem{man} K. F. Man, K. S. Tang and S. Kwong, "Genetic algorithms: concepts and applications [in engineering design]," in IEEE Transactions on Industrial Electronics, vol. 43, no. 5, pp. 519-534, Oct. 1996, doi: 10.1109/41.538609.

\bibitem{abdul} W. Abdulal, O. A. Jadaan, A. Jabas, S. Ramachandram, M. Kaiiali and C. R. Rao, "Rank-Based Genetic Algorithm with Limited Iteration for Grid Scheduling," 2009 First International Conference on Computational Intelligence, Communication Systems and Networks, Indore, 2009, pp. 29-34, doi: 10.1109/CICSYN.2009.23.

\bibitem{kita} M. Takahashi and H. Kita, "A crossover operator using independent component analysis for real-coded genetic algorithms," Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546), Seoul, South Korea, 2001, pp. 643-649 vol. 1, doi: 10.1109/CEC.2001.934452.

\bibitem{im} X. Deng, "Application of Adaptive Genetic Algorithm in Inversion Analysis of Permeability Coefficients," 2008 Second International Conference on Genetic and Evolutionary Computing, Hubei, 2008, pp. 61-65, doi: 10.1109/WGEC.2008.63.

\bibitem{pso} J. Kennedy and R. Eberhart, "Particle swarm optimization," Proceedings of ICNN'95 - International Conference on Neural Networks, Perth, WA, Australia, 1995, pp. 1942-1948 vol.4, doi: 10.1109/ICNN.1995.488968.

\bibitem{gwo} D. Jitkongchuen, P. Phaidang and P. Pongtawevirat, "Grey wolf optimization algorithm with invasion-based migration operation," 2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS), Okayama, 2016, pp. 1-5, doi: 10.1109/ICIS.2016.7550769.

\bibitem{mvo} H. Jia, X. Peng, W. Song, C. Lang, Z. Xing and K. Sun, "Multiverse Optimization Algorithm Based on Lévy Flight Improvement for Multithreshold Color Image Segmentation," in IEEE Access, vol. 7, pp. 32805-32844, 2019, doi: 10.1109/ACCESS.2019.2903345.

\bibitem{cs} M. Naik, M. R. Nath, A. Wunnava, S. Sahany and R. Panda, "A new adaptive Cuckoo search algorithm," 2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS), Kolkata, 2015, pp. 1-5, doi: 10.1109/ReTIS.2015.7232842.

\bibitem{bf} R. W. Garden and A. P. Engelbrecht, "Analysis and classification of optimisation benchmark functions and benchmark suites," 2014 IEEE Congress on Evolutionary Computation (CEC), Beijing, 2014, pp. 1641-1649, doi: 10.1109/CEC.2014.6900240.

\end{thebibliography}


% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}
% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
